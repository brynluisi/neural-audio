{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c02864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cpu\n",
      "AudioMetaData(sample_rate=44100, num_frames=14994001, num_channels=1, bits_per_sample=16, encoding=PCM_S)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module, Parameter\n",
    "from torch import FloatTensor\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device=\", device) \n",
    "\n",
    "import os\n",
    "dirname = os.path.abspath('')\n",
    "rootdir = os.path.split(dirname)[0]\n",
    "\n",
    "H1_TRAINING_INPUT_PATH = \"\".join([rootdir, \"/data/train/ht1-input.wav\"])\n",
    "H1_TRAINING_TARGET_PATH = \"\".join([rootdir, \"/data/train/ht1-target.wav\"])\n",
    "\n",
    "metadata = torchaudio.info(H1_TRAINING_INPUT_PATH)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a3e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_input, sample_rate = torchaudio.load(H1_TRAINING_INPUT_PATH)\n",
    "waveform_target, sample_rate = torchaudio.load(H1_TRAINING_TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee39b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14994001])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eaa622e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a295f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(waveform_input.shape[1] //sample_rate): \n",
    "    sample_input = waveform_input[:,s*sample_rate: ((s+1) * sample_rate)]\n",
    "    sample_target = waveform_target[:,s*sample_rate: ((s+1) * sample_rate)]\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c586dcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 44100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ede7089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 44100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1374785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module): \n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.mlp_stack = nn.Sequential(\n",
    "            nn.Linear(1, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.mlp_stack(x)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8058892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FirstOrderFIRcell(Module):\n",
    "    def __init__(self, b0=1.0, b1=0.0):\n",
    "        super(FirstOrderFIRcell, self).__init__()\n",
    "        self.b0 = Parameter(FloatTensor([b0]))\n",
    "        self.b1 = Parameter(FloatTensor([b1]))\n",
    "\n",
    "    def init_states(self, size):\n",
    "        state = torch.zeros(size).to(self.b0.device) # ? \n",
    "        return state\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        output = self.b0 * input + state\n",
    "        state = self.b1 * input \n",
    "        return output, state\n",
    "\n",
    "class FirstOrderFIR(Module):\n",
    "    def __init__(self):\n",
    "        super(FirstOrderFIR, self).__init__()\n",
    "        self.cell = FirstOrderFIRcell()\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input, initial_states=None):\n",
    "        batch_size = input.shape[0]\n",
    "        sequence_length = input.shape[1]\n",
    "    \n",
    "\n",
    "        if initial_states is None:\n",
    "            states = self.cell.init_states(batch_size)\n",
    "        else:\n",
    "            states = initial_states\n",
    "\n",
    "        out_sequence = torch.zeros(input.shape[:-1]).to(input.device)\n",
    "        for s_idx in range(sequence_length):\n",
    "            out_sequence[:, s_idx], states = self.cell(input[:, s_idx].view(-1), states)\n",
    "        out_sequence = out_sequence.unsqueeze(-1)\n",
    "        \n",
    "\n",
    "        if initial_states is None:\n",
    "            return out_sequence\n",
    "        else:\n",
    "            return out_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a39d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteNetwork(Module): \n",
    "    def __init__(self):\n",
    "        super(CompleteNetwork, self).__init__()\n",
    "        self.FIR = FirstOrderFIR()\n",
    "        self.MLP = MLP()\n",
    "        \n",
    "    def forward(self, x): \n",
    "        \n",
    "        out = self.FIR(x)\n",
    "        return self.MLP(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00086780",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CompleteNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a1a783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class DIIRDataSet(Dataset):\n",
    "    def __init__(self, input, target, sequence_length):\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "        self._sequence_length = sequence_length\n",
    "        self.input_sequence = self.wrap_to_sequences(self.input, self._sequence_length)\n",
    "        self.target_sequence = self.wrap_to_sequences(self.target, self._sequence_length)\n",
    "        self._len = self.input_sequence.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'input': self.input_sequence[index, :, :]\n",
    "               ,'target': self.target_sequence[index, :, :]}\n",
    "\n",
    "    def wrap_to_sequences(self, data, sequence_length):\n",
    "        num_sequences = int(np.floor(data.shape[0] / sequence_length))\n",
    "        truncated_data = data[0:(num_sequences * sequence_length)]\n",
    "        wrapped_data = truncated_data.reshape((num_sequences, sequence_length, 1))\n",
    "        return np.float32(wrapped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfd03b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "fs = 44100\n",
    "f0 = 20\n",
    "f1 = 20e3\n",
    "t = np.linspace(0, 60, 60*int(fs))\n",
    "\n",
    "train_input = signal.chirp(t=t, f0=f0, t1=60, f1=f1, method='logarithmic') + np.random.normal(scale=5e-2, size=len(t))\n",
    "\n",
    "# FIR filter \n",
    "n = 2\n",
    "b = signal.firwin(n, 0.3, window = \"hamming\", pass_zero=True)\n",
    "train_target = signal.filtfilt(b, 1, train_input)\n",
    "\n",
    "\n",
    "# fc = 2e3\n",
    "# sos = signal.butter(N=2, Wn=fc/fs, output='sos')\n",
    "# train_target = signal.sosfilt(sos, train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "392d5b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0139815 ,  0.94593441,  0.87812729, ...,  0.51546728,\n",
       "       -0.68807516,  0.81333108])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c213785e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0139815 ,  0.9459944 ,  0.91859071, ...,  0.04234066,\n",
       "       -0.01183799,  0.81333108])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fdd920b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0518e-05, -3.0518e-05, -3.0518e-05,  ...,  0.0000e+00,\n",
       "          0.0000e+00, -3.0518e-05]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4de38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 1024\n",
    "sequence_length = 512\n",
    "\n",
    "# debug\n",
    "loader = DataLoader(dataset=DIIRDataSet(train_input, train_target, sequence_length), batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c912e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "n_epochs = 100\n",
    "lr = 1e-3\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01450f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(criterion, model, loader, optimizer):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        input_seq_batch = batch['input'].to(device)\n",
    "        target_seq_batch = batch['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predicted_output = model(input_seq_batch)\n",
    "        loss = criterion(target_seq_batch, predicted_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    total_loss /= len(loader)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6250dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- Loss 9.053090E-01\n",
      "Epoch 1 -- Loss 8.659043E-01\n",
      "Epoch 2 -- Loss 8.299149E-01\n",
      "Epoch 3 -- Loss 7.966242E-01\n",
      "Epoch 4 -- Loss 7.657628E-01\n",
      "Epoch 5 -- Loss 7.370465E-01\n",
      "Epoch 6 -- Loss 7.101779E-01\n",
      "Epoch 7 -- Loss 6.848853E-01\n",
      "Epoch 8 -- Loss 6.609420E-01\n",
      "Epoch 9 -- Loss 6.381674E-01\n",
      "Epoch 10 -- Loss 6.164140E-01\n",
      "Epoch 11 -- Loss 5.955585E-01\n",
      "Epoch 12 -- Loss 5.754956E-01\n",
      "Epoch 13 -- Loss 5.561337E-01\n",
      "Epoch 14 -- Loss 5.373936E-01\n",
      "Epoch 15 -- Loss 5.192062E-01\n",
      "Epoch 16 -- Loss 5.015107E-01\n",
      "Epoch 17 -- Loss 4.842526E-01\n",
      "Epoch 18 -- Loss 4.673828E-01\n",
      "Epoch 19 -- Loss 4.508575E-01\n",
      "Epoch 20 -- Loss 4.346375E-01\n",
      "Epoch 21 -- Loss 4.186881E-01\n",
      "Epoch 22 -- Loss 4.029786E-01\n",
      "Epoch 23 -- Loss 3.874831E-01\n",
      "Epoch 24 -- Loss 3.721800E-01\n",
      "Epoch 25 -- Loss 3.570532E-01\n",
      "Epoch 26 -- Loss 3.420916E-01\n",
      "Epoch 27 -- Loss 3.272896E-01\n",
      "Epoch 28 -- Loss 3.126474E-01\n",
      "Epoch 29 -- Loss 2.981717E-01\n",
      "Epoch 30 -- Loss 2.838751E-01\n",
      "Epoch 31 -- Loss 2.697759E-01\n",
      "Epoch 32 -- Loss 2.558987E-01\n",
      "Epoch 33 -- Loss 2.422725E-01\n",
      "Epoch 34 -- Loss 2.289314E-01\n",
      "Epoch 35 -- Loss 2.159130E-01\n",
      "Epoch 36 -- Loss 2.032573E-01\n",
      "Epoch 37 -- Loss 1.910057E-01\n",
      "Epoch 38 -- Loss 1.791995E-01\n",
      "Epoch 39 -- Loss 1.678786E-01\n",
      "Epoch 40 -- Loss 1.570801E-01\n",
      "Epoch 41 -- Loss 1.468368E-01\n",
      "Epoch 42 -- Loss 1.371762E-01\n",
      "Epoch 43 -- Loss 1.281199E-01\n",
      "Epoch 44 -- Loss 1.196853E-01\n",
      "Epoch 45 -- Loss 1.118881E-01\n",
      "Epoch 46 -- Loss 1.047374E-01\n",
      "Epoch 47 -- Loss 9.822451E-02\n",
      "Epoch 48 -- Loss 9.232061E-02\n",
      "Epoch 49 -- Loss 8.698874E-02\n",
      "Epoch 50 -- Loss 8.219165E-02\n",
      "Epoch 51 -- Loss 7.789185E-02\n",
      "Epoch 52 -- Loss 7.405124E-02\n",
      "Epoch 53 -- Loss 7.063131E-02\n",
      "Epoch 54 -- Loss 6.759366E-02\n",
      "Epoch 55 -- Loss 6.490007E-02\n",
      "Epoch 56 -- Loss 6.251317E-02\n",
      "Epoch 57 -- Loss 6.039719E-02\n",
      "Epoch 58 -- Loss 5.851856E-02\n",
      "Epoch 59 -- Loss 5.684625E-02\n",
      "Epoch 60 -- Loss 5.535202E-02\n",
      "Epoch 61 -- Loss 5.401061E-02\n",
      "Epoch 62 -- Loss 5.279958E-02\n",
      "Epoch 63 -- Loss 5.169931E-02\n",
      "Epoch 64 -- Loss 5.069286E-02\n",
      "Epoch 65 -- Loss 4.976569E-02\n",
      "Epoch 66 -- Loss 4.890548E-02\n",
      "Epoch 67 -- Loss 4.810188E-02\n",
      "Epoch 68 -- Loss 4.734626E-02\n",
      "Epoch 69 -- Loss 4.663145E-02\n",
      "Epoch 70 -- Loss 4.595156E-02\n",
      "Epoch 71 -- Loss 4.530173E-02\n",
      "Epoch 72 -- Loss 4.467799E-02\n",
      "Epoch 73 -- Loss 4.407706E-02\n",
      "Epoch 74 -- Loss 4.349634E-02\n",
      "Epoch 75 -- Loss 4.293363E-02\n",
      "Epoch 76 -- Loss 4.238716E-02\n",
      "Epoch 77 -- Loss 4.185555E-02\n",
      "Epoch 78 -- Loss 4.133751E-02\n",
      "Epoch 79 -- Loss 4.083210E-02\n",
      "Epoch 80 -- Loss 4.033848E-02\n",
      "Epoch 81 -- Loss 3.985594E-02\n",
      "Epoch 82 -- Loss 3.938388E-02\n",
      "Epoch 83 -- Loss 3.892178E-02\n",
      "Epoch 84 -- Loss 3.846924E-02\n",
      "Epoch 85 -- Loss 3.802583E-02\n",
      "Epoch 86 -- Loss 3.759123E-02\n",
      "Epoch 87 -- Loss 3.716511E-02\n",
      "Epoch 88 -- Loss 3.674722E-02\n",
      "Epoch 89 -- Loss 3.633726E-02\n",
      "Epoch 90 -- Loss 3.593505E-02\n",
      "Epoch 91 -- Loss 3.554033E-02\n",
      "Epoch 92 -- Loss 3.515294E-02\n",
      "Epoch 93 -- Loss 3.477266E-02\n",
      "Epoch 94 -- Loss 3.439935E-02\n",
      "Epoch 95 -- Loss 3.403282E-02\n",
      "Epoch 96 -- Loss 3.367261E-02\n",
      "Epoch 97 -- Loss 3.331513E-02\n",
      "Epoch 98 -- Loss 3.294637E-02\n",
      "Epoch 99 -- Loss 3.254854E-02\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    loss = train(criterion, model, loader, optimizer)\n",
    "    print(\"Epoch {} -- Loss {:3E}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "640f2b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.0144], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.FIR.cell.b0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34df8c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2343], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.FIR.cell.b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61dac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[n] = b0* x[n] + b1 * x[n-1] + Wx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3288a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to github \n",
    "\n",
    "# compare the target to output on FIR example \n",
    "\n",
    "# FIR talk about CNN implementation\n",
    "\n",
    "# IIR filter (biquads)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
